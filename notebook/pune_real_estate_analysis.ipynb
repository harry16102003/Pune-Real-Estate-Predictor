{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a9669e-1574-4182-adef-57bd03aa0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0cf884-b161-47c8-933b-7244eb400ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTANT: Your Database Credentials ---\n",
    "db_user = 'root'\n",
    "db_password = 'harsh'\n",
    "db_host = 'localhost'\n",
    "db_name = 'pune_real_estate_db'\n",
    "table_name = 'raw_house_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdfc98a1-877b-4891-b995-51b6404f6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create the Database Connection String ---\n",
    "# This string tells pandas how to connect to your database.\n",
    "db_connection_str = f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a055b21-f54b-4ac2-bb69-195a73aa106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from SQL into DataFrame.\n",
      "Shape of the DataFrame: (12711, 10)\n",
      "\n",
      "First 5 rows of the data:\n",
      "   id             area_type   availability                  location  \\\n",
      "0   1  Super built-up  Area         19-Dec  Electronic City Phase II   \n",
      "1   2            Plot  Area  Ready To Move          Chikka Tirupathi   \n",
      "2   3        Built-up  Area  Ready To Move               Uttarahalli   \n",
      "3   4  Super built-up  Area  Ready To Move        Lingadheeranahalli   \n",
      "4   5  Super built-up  Area  Ready To Move                  Kothanur   \n",
      "\n",
      "        size  society total_sqft  bath  balcony   price  \n",
      "0      2 BHK  Coomee        1056   2.0      1.0   39.07  \n",
      "1  4 Bedroom  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      3 BHK                1440   2.0      3.0   62.00  \n",
      "3      3 BHK  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      2 BHK                1200   2.0      1.0   51.00  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Create the Database Engine ---\n",
    "    db_connection = create_engine(db_connection_str)\n",
    "\n",
    "    # --- Load Data into a Pandas DataFrame ---\n",
    "    # This query selects all data from your table.\n",
    "    df = pd.read_sql(f'SELECT * FROM {table_name}', con=db_connection)\n",
    "\n",
    "    # --- Verify the Import ---\n",
    "    print(\"Successfully loaded data from SQL into DataFrame.\")\n",
    "    print(f\"Shape of the DataFrame: {df.shape}\") # (rows, columns)\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"\\nPlease check the following:\")\n",
    "    print(\"1. Is your MySQL server running?\")\n",
    "    print(\"2. Did you update 'your_password' in the script correctly?\")\n",
    "    print(\"3. Is the database name and table name correct?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef379e5-4be6-442d-b13a-81cffdb804ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy to keep the original raw dataframe safe\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46730705-d3d9-4719-9f82-cc4c999744e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Handle Missing Values ---\n",
    "# For 'bath' and 'balcony', we fill missing values with the median.\n",
    "# The syntax below is the modern way to do this and avoids the FutureWarning.\n",
    "df_clean['bath'] = df_clean['bath'].fillna(df_clean['bath'].median())\n",
    "df_clean['balcony'] = df_clean['balcony'].fillna(df_clean['balcony'].median())\n",
    "\n",
    "# Drop rows where 'location' or 'size' are missing, as they are critical.\n",
    "df_clean.dropna(subset=['location', 'size'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bcb231-c926-42e0-8499-3784e382f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Clean the 'size' column and create 'bhk' ---\n",
    "# The .str.split() method splits the string by space, and .str[0] gets the first part (the number).\n",
    "# pd.to_numeric converts it to a number. 'coerce' turns any errors into NaN (Not a Number).\n",
    "df_clean['bhk'] = pd.to_numeric(df_clean['size'].str.split().str[0], errors='coerce')\n",
    "df_clean.dropna(subset=['bhk'], inplace=True) # Drop rows where conversion failed\n",
    "df_clean['bhk'] = df_clean['bhk'].astype(int) # Convert to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664a7ad3-d319-4161-87f8-e52eb0c2886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Clean the 'total_sqft' column ---\n",
    "# This function handles ranges like '1133 - 1384' by taking their average.\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        try:\n",
    "            # For a range, return the average\n",
    "            return (float(tokens[0]) + float(tokens[1])) / 2\n",
    "        except ValueError:\n",
    "            return None # Return None if conversion fails\n",
    "    try:\n",
    "        # For a single number, just convert it\n",
    "        return float(x)\n",
    "    except (ValueError, TypeError):\n",
    "        return None # Return None for other weird values\n",
    "\n",
    "df_clean['total_sqft'] = df_clean['total_sqft'].apply(convert_sqft_to_num)\n",
    "df_clean.dropna(subset=['total_sqft'], inplace=True) # Drop rows where conversion failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3600190f-2c25-4ef1-aa8e-f1a1fcc5f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Drop columns not needed for the model ---\n",
    "df_model_ready = df_clean.drop(columns=['id', 'area_type', 'availability', 'size', 'society'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9281c6eb-3f4e-466b-81d7-3a488e599595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and feature engineering complete.\n",
      "Shape of the final DataFrame: (12669, 6)\n",
      "\n",
      "First 5 rows of the cleaned data:\n",
      "                   location  total_sqft  bath  balcony   price  bhk\n",
      "0  Electronic City Phase II      1056.0   2.0      1.0   39.07    2\n",
      "1          Chikka Tirupathi      2600.0   5.0      3.0  120.00    4\n",
      "2               Uttarahalli      1440.0   2.0      3.0   62.00    3\n",
      "3        Lingadheeranahalli      1521.0   3.0      1.0   95.00    3\n",
      "4                  Kothanur      1200.0   2.0      1.0   51.00    2\n",
      "\n",
      "Data types of the columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12669 entries, 0 to 12710\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   location    12669 non-null  object \n",
      " 1   total_sqft  12669 non-null  float64\n",
      " 2   bath        12669 non-null  float64\n",
      " 3   balcony     12669 non-null  float64\n",
      " 4   price       12669 non-null  float64\n",
      " 5   bhk         12669 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 692.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Verify the cleaned data ---\n",
    "print(\"Data cleaning and feature engineering complete.\")\n",
    "print(f\"Shape of the final DataFrame: {df_model_ready.shape}\")\n",
    "print(\"\\nFirst 5 rows of the cleaned data:\")\n",
    "print(df_model_ready.head())\n",
    "print(\"\\nData types of the columns:\")\n",
    "print(df_model_ready.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61985bee-139c-4a90-9e0f-dd78cb98d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the dataframe from the previous step\n",
    "df_prep = df_model_ready.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae229a21-bb20-4ee6-95d2-dcded5c956d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Outlier Removal based on Business Logic ---\n",
    "# It's unusual to have a house where the sq. ft. per bedroom is less than 300.\n",
    "# We will remove such outliers.\n",
    "df_prep = df_prep[~(df_prep['total_sqft'] / df_prep['bhk'] < 300)]\n",
    "\n",
    "# It's also unusual for the number of bathrooms to be more than the number of bedrooms + 2.\n",
    "df_prep = df_prep[df_prep.bath < df_prep.bhk + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a644882-444c-4d54-b146-cca47aac3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Feature Engineering: Create price_per_sqft ---\n",
    "# This is a very important feature for identifying location-based price outliers.\n",
    "# Price is in Lakhs, so we multiply by 100,000.\n",
    "df_prep['price_per_sqft'] = df_prep['price'] * 100000 / df_prep['total_sqft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd30642-2a81-44fa-b43a-263450fba13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Outlier Removal based on price_per_sqft ---\n",
    "# For each location, we will remove data points that are beyond one standard deviation\n",
    "# from the mean price_per_sqft for that location.\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = subdf.price_per_sqft.mean()\n",
    "        st = subdf.price_per_sqft.std()\n",
    "        reduced_df = subdf[(subdf.price_per_sqft > (m - st)) & (subdf.price_per_sqft < (m + st))]\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "df_prep = remove_pps_outliers(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f01560a5-edf6-4d91-91ae-34395b9b9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Prepare for Modeling: One-Hot Encoding for 'location' ---\n",
    "# Machine learning models need all data to be numeric. We convert the 'location'\n",
    "# column into many new columns, each representing a location.\n",
    "dummies = pd.get_dummies(df_prep.location)\n",
    "\n",
    "# To avoid the \"dummy variable trap,\" we drop one column.\n",
    "df_final = pd.concat([df_prep.drop('location', axis='columns'), dummies.drop('other', axis='columns', errors='ignore')], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c2e258-f6e9-49d5-a494-1d2177cc72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Final Cleanup ---\n",
    "# We can now drop the 'price_per_sqft' column as it was only used for outlier detection.\n",
    "df_final = df_final.drop('price_per_sqft', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cc96da6-7f8e-4ca2-b070-9fe058e7b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier removal and final preparation complete.\n",
      "Shape of the final modeling DataFrame: (9151, 760)\n",
      "\n",
      "First 5 rows of the final data:\n",
      "   total_sqft  bath  balcony  price  bhk   Devarabeesana Halli  \\\n",
      "0      1100.0   2.0      1.0   70.0    2                  True   \n",
      "1      1672.0   3.0      2.0  150.0    3                  True   \n",
      "2      1750.0   3.0      3.0  149.0    3                  True   \n",
      "3      1750.0   3.0      2.0  150.0    3                  True   \n",
      "4      1250.0   2.0      3.0   44.0    3                 False   \n",
      "\n",
      "    Devarachikkanahalli   Electronic City   Mysore Highway   Rachenahalli  \\\n",
      "0                 False             False            False          False   \n",
      "1                 False             False            False          False   \n",
      "2                 False             False            False          False   \n",
      "3                 False             False            False          False   \n",
      "4                  True             False            False          False   \n",
      "\n",
      "   ...  Yelahanka  Yelahanka New Town  Yelenahalli  Yemlur  Yeshwanthpur  \\\n",
      "0  ...      False               False        False   False         False   \n",
      "1  ...      False               False        False   False         False   \n",
      "2  ...      False               False        False   False         False   \n",
      "3  ...      False               False        False   False         False   \n",
      "4  ...      False               False        False   False         False   \n",
      "\n",
      "   Yeshwanthpur Industrial Suburb  cooketown  frazertown  manyata park  \\\n",
      "0                           False      False       False         False   \n",
      "1                           False      False       False         False   \n",
      "2                           False      False       False         False   \n",
      "3                           False      False       False         False   \n",
      "4                           False      False       False         False   \n",
      "\n",
      "   tc.palya  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "\n",
      "[5 rows x 760 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Verify the Final DataFrame ---\n",
    "print(\"Outlier removal and final preparation complete.\")\n",
    "print(f\"Shape of the final modeling DataFrame: {df_final.shape}\")\n",
    "print(\"\\nFirst 5 rows of the final data:\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eebe8f0-efd0-43d9-a25f-c0eb93699e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8766d75d-8d97-411b-bfa1-b2288ff7e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Features (X) and Target (y) ---\n",
    "X = df_final.drop('price', axis='columns')\n",
    "y = df_final['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eda0f7f-7cce-4702-a1bf-f5334ee7ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Split Data into Training and Testing Sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e438ac2-8d39-4c3c-bb71-6f1f7a01e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the XGBoost model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Initialize and Train the XGBoost Model ---\n",
    "print(\"Training the XGBoost model...\")\n",
    "model = xgboost.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=5, subsample=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065d915d-eff4-4437-af71-dda220d85464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "R-squared (R2 Score): 0.73\n",
      "Mean Absolute Error (MAE): 18.03 Lakhs\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Evaluate the Model's Performance ---\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"R-squared (R2 Score): {r2:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} Lakhs\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e119f801-cd5b-4931-936a-d18e83f502f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Save Model Files ---\n",
    "joblib.dump(model, '../models/pune_house_price_model.pkl')\n",
    "columns_data = {'columns': [col.lower() for col in X.columns.tolist()]}\n",
    "with open('../models/model_columns.json', 'w') as f:\n",
    "    json.dump(columns_data, f)\n",
    "print(\"\\nModel files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac60150-4135-43fe-8d45-08abaf5a5a24",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../data/dashboard_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dashboard_df \u001b[38;5;241m=\u001b[39m df_prep\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_per_sqft\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m dashboard_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/dashboard_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdashboard_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdashboard_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDashboard data successfully saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdashboard_csv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../data/dashboard_data.csv'"
     ]
    }
   ],
   "source": [
    "# --- 6. (NEW) Save the Correct Data for the Dashboard ---\n",
    "# We use the 'df_prep' DataFrame from the previous cell, before one-hot encoding.\n",
    "dashboard_df = df_prep.drop(columns=['price_per_sqft'])\n",
    "dashboard_csv_path = '../data/dashboard_data.csv'\n",
    "dashboard_df.to_csv(dashboard_csv_path, index=False)\n",
    "print(f\"Dashboard data successfully saved to: {dashboard_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dece69-bddc-4a3b-890b-9489f750bf61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
